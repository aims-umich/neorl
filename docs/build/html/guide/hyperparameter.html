

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Hyperparameter Tuning &mdash; NEORL 1.7 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme_overrides.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Advantage Actor Critic (A2C)" href="../modules/a2c.html" />
    <link rel="prev" title="Evolutionary Algorithms" href="evolu.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> NEORL
          

          
            
            <img src="../_static/logo.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                main (1.7 )
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">General Guide</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="install.html">Quick Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="detinstall.html">Detailed Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="quickstart.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="rl.html">Reinforcement Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="evolu.html">Evolutionary Algorithms</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Hyperparameter Tuning</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#grid-search">Grid Search</a></li>
<li class="toctree-l2"><a class="reference internal" href="#random-search">Random Search</a></li>
<li class="toctree-l2"><a class="reference internal" href="#bayesian-search">Bayesian Search</a></li>
<li class="toctree-l2"><a class="reference internal" href="#evolutionary-search">Evolutionary Search</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Algorithms</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../modules/a2c.html">Advantage Actor Critic (A2C)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/acer.html">Actor-Critic with Experience Replay (ACER)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/acktr.html">Actor Critic using Kronecker-Factored Trust Region (ACKTR)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/dqn.html">Deep Q Learning (DQN)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/ppo2.html">Proximal Policy Optimisation (PPO)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/es.html">Evolution Strategies (<span class="math notranslate nohighlight">\(\mu,\lambda\)</span>) (ES)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/pso.html">Particle Swarm Optimisation (PSO)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/de.html">Differential Evolution (DE)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/xnes.html">Exponential Natural Evolution Strategies (XNES)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/gwo.html">Grey Wolf Optimizer (GWO)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/pesa.html">Prioritized replay Evolutionary and Swarm Algorithm (PESA)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/pesa2.html">Modern PESA (PESA2)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/sa.html">Simulated Annealing (SA)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/ssa.html">Salp Swarm Algorithm (SSA)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/woa.html">Whale Optimization Algorithm (WOA)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/mfo.html">Moth-flame Optimization (MFO)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/jaya.html">JAYA Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/bat.html">Bat Algorithm (BAT)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/hho.html">Harris Hawks Optimization (HHO)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/fneat.html">Feedforward Neuroevolution of Augmenting Topologies (FNEAT)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/rneat.html">Recurrent Neuroevolution of Augmenting Topologies (RNEAT)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/ppoes.html">RL-informed Evolution Strategies (PPO-ES)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/ackde.html">RL-informed Differential Evolution (ACKTR-DE)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/aco.html">Ant Colony Optimization (ACO)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/nga.html">Neural Genetic Algorithms (NGA)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/nhho.html">Neural Harris Hawks Optimization (NHHO)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/cs.html">Cuckoo Search (CS)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/ts.html">Tabu Search (TS)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Hyperparameter Tuning</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tune/grid.html">Grid Search</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tune/random.html">Random Search</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tune/bayes.html">Bayesian Search</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tune/evolu.html">Evolutionary Search</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../examples/ex1.html">Example 1: Traveling Salesman Problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/ex2.html">Example 2: Ackley with EA</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/ex3.html">Example 3: Welded-beam design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/ex4.html">Example 4: Benchmarks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/ex5.html">Example 5: CEC’2017 Test Suite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/ex6.html">Example 6: Three-bar Truss Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/ex7.html">Example 7: Pressure Vessel Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/ex8.html">Example 8: Pressure Vessel Design with Demonstration of Categorical Parameter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/ex9.html">Example 9: Cantilever Stepped Beam</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/ex10.html">Example 10: Knapsack Problem</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Misc</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../misc/changelog.html">Changelog</a></li>
<li class="toctree-l1"><a class="reference internal" href="../misc/projects.html">Projects</a></li>
<li class="toctree-l1"><a class="reference internal" href="../misc/contrib.html">Contributors</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">NEORL</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Hyperparameter Tuning</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/guide/hyperparameter.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="hyperparameter-tuning">
<span id="hyperparameter"></span><h1>Hyperparameter Tuning<a class="headerlink" href="#hyperparameter-tuning" title="Permalink to this headline">¶</a></h1>
<p>Hyperparameter tuning is the problem of choosing a set of optimal hyperparameters for a learning algorithm, which includes reinforcement learning, evolutionary, and neuroevolution algorithms of NEORL. Hyperparameter tuning is effective to maximize the efficiency of the optimization algorithm in hand. In NEORL, we provide different methods to tune hyperparameters, which are highlighted briefly here.</p>
<div class="section" id="grid-search">
<h2>Grid Search<a class="headerlink" href="#grid-search" title="Permalink to this headline">¶</a></h2>
<p>See the <a class="reference internal" href="../tune/grid.html#grid"><span class="std std-ref">Grid Search</span></a> section</p>
<p>Original paper: Bergstra, J., &amp; Bengio, Y. (2012). Random search for hyper-parameter optimization. Journal of machine learning research, 13(2).</p>
<p>Grid Search is an exhaustive search for selecting an optimal set of algorithm hyperparameters. In Grid Search, the analyst sets up a grid of hyperparameter values. A multi-dimensional full grid of all hyperparameters is constructed, which contains all possible combinations of hyperparameters. Afterwards, every combination of hyperparameter values is tested in serial/parallel, where the optimization score (e.g. fitness) is estimated. Grid search can be very expensive for fine grids as well as large number of hyperparameters to tune.</p>
<a class="reference internal image-reference" href="../_images/grid.png"><img alt="alternate text" class="align-center" src="../_images/grid.png" style="width: 273.6px; height: 296.0px;" /></a>
<p>For example, to tune few hyperparameters of DQN, the following grids can be defined:</p>
<div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learning_rate</span></code> =[0.0001, 0.00025, 0.0005, 0.00075, 0.001]</div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">batch_size</span></code> =[16, 32, 64]</div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">target_network_update_freq</span></code> =[100, 250, 500, 750, 1000, 1250, 1500, 1750, 2000]</div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">exploration_fraction</span></code> =[0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35]</div>
</div>
<p>The full grid has a size of = 5*3*9*7= 945 (A total of 945 hyperparameter combinations will be evaluated). Therefore, the cost of grid search is:</p>
<div class="math notranslate nohighlight">
\[Cost = k_1 \times k_2 \times ... \times k_d,\]</div>
<p>where <span class="math notranslate nohighlight">\(k_i\)</span> is the number of nodes in the hyperparameter <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(d\)</span> is the number of hyperparameters to tune.</p>
</div>
<div class="section" id="random-search">
<h2>Random Search<a class="headerlink" href="#random-search" title="Permalink to this headline">¶</a></h2>
<p>See the <a class="reference internal" href="../tune/random.html#random"><span class="std std-ref">Random Search</span></a> section</p>
<p>Original paper: Bergstra, J., &amp; Bengio, Y. (2012). Random search for hyper-parameter optimization. Journal of machine learning research, 13(2).</p>
<p>Random search is a technique where random combinations of the hyperparameters are used to find the best solution for the algorithm used. Random search tries random combinations of the hyperparameter set, where the cost function is evaluated at these random sets in the parameter space. As indicated by the reference above, the chances of finding the optimal hyperparameters are comparatively higher in random search than grid search. This is because of the random search pattern, as the algorithm might end up being used on the optimized hyperparameters without any aliasing or wasting of resources.</p>
<a class="reference internal image-reference" href="../_images/random.png"><img alt="alternate text" class="align-center" src="../_images/random.png" style="width: 281.6px; height: 314.40000000000003px;" /></a>
<p>For example, to tune few hyperparameters of DQN, the parameters can be defined depending on the type:</p>
<div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learning_rate</span></code> = <span class="math notranslate nohighlight">\(\mathcal{U}(0.0001, 0.001)\)</span> (Parameter type is continuous <code class="docutils literal notranslate"><span class="pre">float</span></code> uniform distribution)</div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">batch_size</span></code> = <span class="math notranslate nohighlight">\(\mathcal{U}  \{16, 64\}\)</span> (Parameter type is discrete <code class="docutils literal notranslate"><span class="pre">int</span></code> uniform distribution)</div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">target_network_update_freq</span></code> = <span class="math notranslate nohighlight">\(\mathcal{C}  \{100, 500, 1000, 1500\}\)</span> (Parameter type is categorical <code class="docutils literal notranslate"><span class="pre">grid</span></code>)</div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">exploration_fraction</span></code> = <span class="math notranslate nohighlight">\(\mathcal{C}\{0.05, 0.1, 0.15\}\)</span> (Parameter type is categorical <code class="docutils literal notranslate"><span class="pre">grid</span></code>)</div>
</div>
<p>The cost of random search is determined by the total number of random evaluations provided by the user (<code class="docutils literal notranslate"><span class="pre">ncases</span></code>).</p>
</div>
<div class="section" id="bayesian-search">
<h2>Bayesian Search<a class="headerlink" href="#bayesian-search" title="Permalink to this headline">¶</a></h2>
<p>See the <a class="reference internal" href="../tune/bayes.html#bayes"><span class="std std-ref">Bayesian Search</span></a> section</p>
<p>Original paper: <a class="reference external" href="https://arxiv.org/abs/1012.2599">https://arxiv.org/abs/1012.2599</a></p>
<p>Bayesian search, in contrast to grid and random searches, keeps track of past evaluation results. Bayesian uses past evaluations to form a probabilistic model mapping hyperparameters to a probability of a score on the objective function (e.g. max/min fitness). Bayesian optimization excels when the objective functions are expensive to evaluate, when we do not have access to derivatives, or when the problem at hand is non-convex.</p>
<p>The heart of Bayesian optimization is Bayes theorem, which updates our prior beliefs (e.g. hyperparameter values) after new evidence/data is observed (e.g. new fitness values found by the algorithm of interest). The updated beliefs are represented by the posterior distribution, which is used to guide the next round of hyperparameter sampling. Also, Bayesian optimization combines the concepts of “surrogate” models (e.g. Gaussian processes) to accelerate the search, and the “acquisition” function to guide sampling from the posterior  distribution, which both can effectively make a robust search toward the global optima of the cost function (see the Figure below). The sequential-nature of Bayesian optimization makes its parallelization complex and not natural as grid/random/evolutionary search, which is the obvious downside of Bayesian optimization.</p>
<a class="reference internal image-reference" href="../_images/bayes.png"><img alt="alternate text" class="align-center" src="../_images/bayes.png" style="width: 774.0px; height: 492.0px;" /></a>
<p>For example, to tune few hyperparameters of DQN by Bayesian search, the parameter space can be defined as:</p>
<div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learning_rate</span></code> = <span class="math notranslate nohighlight">\(\mathcal{U}(0.0001, 0.001)\)</span> (Parameter type is continuous <code class="docutils literal notranslate"><span class="pre">float</span></code> uniform distribution)</div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">batch_size</span></code> = <span class="math notranslate nohighlight">\(\mathcal{U}  \{16, 64\}\)</span> (Parameter type is discrete <code class="docutils literal notranslate"><span class="pre">int</span></code> uniform distribution)</div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">target_network_update_freq</span></code> = <span class="math notranslate nohighlight">\(\mathcal{C}  \{100, 500, 1000, 1500\}\)</span> (Parameter type is categorical <code class="docutils literal notranslate"><span class="pre">grid</span></code>)</div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">exploration_fraction</span></code> = <span class="math notranslate nohighlight">\(\mathcal{C}\{0.05, 0.1, 0.15\}\)</span> (Parameter type is categorical <code class="docutils literal notranslate"><span class="pre">grid</span></code>)</div>
</div>
<p>The cost of Bayesian search is determined by the total number of fitness evaluations provided by the user (<code class="docutils literal notranslate"><span class="pre">ncases</span></code>).</p>
</div>
<div class="section" id="evolutionary-search">
<h2>Evolutionary Search<a class="headerlink" href="#evolutionary-search" title="Permalink to this headline">¶</a></h2>
<p>See the <a class="reference internal" href="../tune/evolu.html#evolsearch"><span class="std std-ref">Evolutionary Search</span></a> section</p>
<p>Original paper: E. Bochinski, T. Senst and T. Sikora, “Hyper-parameter optimization for convolutional neural network committees based on evolutionary algorithms,” 2017 IEEE International Conference on Image Processing (ICIP), Beijing, China, 2017, pp. 3924-3928, doi: 10.1109/ICIP.2017.8297018.</p>
<p>We have used a compact evolution strategy (ES) module for the purpose of tuning the hyperparameters of NEORL algorithms. See the <a class="reference internal" href="../modules/es.html#es"><span class="std std-ref">ES algorithm</span></a> section for more details about the (<span class="math notranslate nohighlight">\(\mu,\lambda\)</span>) algorithm. To reduce the burden on the users, we specified and adapt all ES tuner hyperparameters, so the user needs to specify the hyperparameter space similar to grid, random, and Bayesian search methods. ES tuner leverages a population of individuals, where each individual represents a sample from the hyperparameter space. ES uses recombination, crossover, and mutation operations to improve the individuals from generation to the other. The best of the best individuals in all generations are reported as the top hyperparameter sets for the algorithm (See the Figure below).</p>
<a class="reference internal image-reference" href="../_images/genetic.png"><img alt="alternate text" class="align-center" src="../_images/genetic.png" style="width: 796.8px; height: 374.4px;" /></a>
<p>Setting up the hyperparameter space for evolutionary search is quite similar to Bayesian search. Lastly, the cost of evolutionary search is determined by the total number of evaluated individuals in the population over all generations (<code class="docutils literal notranslate"><span class="pre">ngen</span> <span class="pre">*</span>&#160; <span class="pre">npop</span></code>), where <code class="docutils literal notranslate"><span class="pre">npop=10</span></code> and <code class="docutils literal notranslate"><span class="pre">ngen</span></code> is left for the user to decide.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="../modules/a2c.html" class="btn btn-neutral float-right" title="Advantage Actor Critic (A2C)" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="evolu.html" class="btn btn-neutral float-left" title="Evolutionary Algorithms" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, Exelon Corp. &amp; MIT.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>